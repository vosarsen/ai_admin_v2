# Redis кеширование контекста диалогов - 31 июля 2025

## Контекст

После анализа диалога с клиентом Алексеем (+7 916 367-47-23) была выявлена критическая проблема: AI терял контекст диалога через 5-7 минут из-за истечения времени жизни in-memory кеша.

### Проблема:
- Контекст хранился в `Map()` в памяти каждого воркера
- TTL составлял всего 5 минут
- При масштабировании клиент мог попасть на другой воркер
- После рестарта весь контекст терялся

### Последствия:
- AI забывал о чем говорили ранее
- Повторно спрашивал имя клиента
- Терял контекст услуги и даты
- Создавал плохой UX для клиентов

## Решение

Реализовано Redis кеширование полного контекста диалога с TTL 12 часов.

### Архитектурные изменения:

1. **Удален in-memory кеш:**
   - Убран `contextCache = new Map()`
   - Удален метод `cleanupCache()`
   - Убран `setInterval` для очистки

2. **Добавлены методы в ContextService:**
   ```javascript
   // Получение кешированного контекста
   async getCachedFullContext(phone, companyId)
   
   // Сохранение контекста с TTL
   async setCachedFullContext(phone, companyId, context, ttl = 12 * 60 * 60)
   
   // Инвалидация кеша
   async invalidateCachedContext(phone, companyId)
   ```

3. **Изменен loadFullContext в AI Admin v2:**
   - Сначала проверяет Redis кеш
   - При отсутствии загружает из БД
   - Сохраняет в Redis на 12 часов

4. **Добавлена инвалидация кеша:**
   - При создании записи
   - При отмене записи

## Технические детали

### Проблема с Redis Proxy

Столкнулись с проблемой двойного префикса: Redis proxy в ContextService добавлял префикс "context:" ко всем ключам, что приводило к ключам вида `context:full_context:962302:+79001234567`.

**Решение:** Использовать `redisRaw` вместо `redis` для методов работы с full_context.

### Конфигурация портов

Для локальной разработки используется SSH туннель на порту 6380, а на сервере Redis на 6379.

**Решение:** Добавлена динамическая конфигурация в `redis-config.js`:
```javascript
const isLocal = process.env.NODE_ENV === 'development' || !process.env.NODE_ENV;
const port = isLocal ? 6380 : 6379;
```

### Размер контекста

Средний размер полного контекста: ~300KB
- Включает: информацию о компании, клиенте, услугах, персонале, расписании
- При TTL 12 часов и 1000 активных клиентов: ~300MB памяти Redis

## Результаты тестирования

### Производительность:
- **Загрузка из БД**: 8.2 секунды
- **Загрузка из Redis**: 2.7 секунды (в 3 раза быстрее)
- **Инвалидация**: < 100ms

### Преимущества:
1. **Долгий контекст**: 12 часов вместо 5 минут
2. **Единый кеш**: для всех воркеров
3. **Персистентность**: переживает рестарты
4. **Масштабируемость**: готово для роста нагрузки

## Проблемы и решения

1. **Проблема**: Redis proxy добавлял двойной префикс
   - **Решение**: Использовать `redisRaw` для full_context операций

2. **Проблема**: Разные порты для локальной разработки и сервера
   - **Решение**: Динамическая конфигурация на основе NODE_ENV

3. **Проблема**: Большой размер контекста (~300KB)
   - **Решение**: Приемлемо для текущих объемов, в будущем можно добавить сжатие

## Выводы

Redis кеширование решило проблему потери контекста и улучшило производительность. Система готова к масштабированию и увеличению нагрузки. Клиенты больше не будут сталкиваться с "забывчивым" ботом.

## Следующие шаги

1. Мониторинг cache hit rate в production
2. Добавление метрик в Grafana
3. Рассмотреть сжатие контекста (gzip) для экономии памяти
4. Добавить прогрев кеша для VIP клиентов